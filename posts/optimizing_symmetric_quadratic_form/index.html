<!doctype html> <html lang=en > <meta charset=UTF-8 > <meta name=viewport  content="width=device-width, initial-scale=1"> <link rel=stylesheet  href="/libs/katex/katex.min.css"> <link rel=stylesheet  href="/libs/highlight/github.min.css"> <link rel=stylesheet  href="/css/tachyons.css"> <link rel=icon  href="/assets/favicon.png"> <link rel=preconnect  href="https://fonts.gstatic.com"> <link href="https://fonts.googleapis.com/css2?family=PT+Serif:ital,wght@0,400;0,700;1,400;1,700&display=swap" rel=stylesheet > <title>Optimizing Symmetric Quadratic Form</title> <style> body { font-size: 16px; background: #111111; line-height: 1.8; font-family: "PT Serif", sans-serif; margin: 0 auto 0 auto; color: #EEEEEE; } a { color: silver; border-bottom: 3px solid #e1e1e1; text-decoration: none; transition: opacity .15s ease-in; } a:hover,a:focus { color: #F4F4F4; border-bottom: 3px solid #c1c1c1; transition: opacity .15s ease-in; } .colbox-blue { background-color: #eef3f5; padding-top: 5px; padding-right: 10px; padding-left: 10px; padding-bottom: 5px; margin-left: 5px; margin-top: 5px; margin-bottom: 5px; border-radius: 0 10px 10px 0; border-left: 5px solid #4c9cf1; } blockquote { background: var(--block-background); border-left: 7px solid #a8a8a8; margin: 1.5em 10px; padding: 0.5em 10px; font-style: italic; } blockquote p { display: inline; } .hljs { font-family: "Fira Code", monospace; font-size: 14px; line-height: 1.35em; border-radius: 2px; } </style> <div class="pa5 pt4 pb4" style="margin: 0 auto; max-width: 900px; background: #333333"> <header> <div class="f2 lh-copy b"><a href="/" class="bn dim normal silver">Loop Compiler</a></div> <nav> <ul class="flex list pl0 bt bb b--light-silver mb4"> <li class="pa2 pl0"><a class="bn dim" href="/">Home</a> </ul> </nav> </header> <h1 class="f2 lh-title normal light-gray">Optimizing Symmetric Quadratic Form</h1> <div class="f5 lh-copy i gray">2022-12-19</div> <div class=franklin-content > <p>This post is motivated by <a href="https://discourse.julialang.org/t/faster-quadratic-expression-for-symmetric-matrices/91843">this</a> discourse thread, providing the following code:</p> <pre><code class="julia hljs"><span class=hljs-keyword >using</span> LinearAlgebra, MKL, BenchmarkTools, LoopVectorization
product_1(x, M) = dot(x, M, x)

<span class=hljs-keyword >function</span> product_2(x, M) 
    Mx = M * x
    <span class=hljs-keyword >return</span> dot(x, Mx)
<span class=hljs-keyword >end</span>
<span class=hljs-keyword >function</span> product_3(x, M)
    n = length(x)
    result = zero(eltype(x))

    <span class=hljs-meta >@inbounds</span> <span class=hljs-keyword >for</span> i = <span class=hljs-number >1</span>:n
        result += x[i]^<span class=hljs-number >2</span> * M[i, i]

        <span class=hljs-meta >@simd</span> <span class=hljs-keyword >for</span> j = <span class=hljs-number >1</span> : i - <span class=hljs-number >1</span>
            result += <span class=hljs-number >2</span>* x[i] * x[j] * M[j, i]
        <span class=hljs-keyword >end</span> 
    <span class=hljs-keyword >end</span>

    <span class=hljs-keyword >return</span> result
<span class=hljs-keyword >end</span></code></pre> <p>The author expressed surprise that making matrix <code>M</code> symmetric wasn&#39;t always faster, and also that <code>product_3</code>, explicitly taking advantage of that symmetry, was slowest.</p> <p>Setting a baseline:</p> <pre><code class="julia hljs">BLAS.set_num_threads(<span class=hljs-number >1</span>) <span class=hljs-comment ># single threaded `product_2`</span>
x = rand(<span class=hljs-number >200</span>);
A = rand(length(x), <span class=hljs-number >2</span>+length(x)) |&gt; y -&gt; y*y&#x27;;
B = Symmetric(A, :U);
<span class=hljs-meta >@btime</span> product_1($x, $A)
<span class=hljs-meta >@btime</span> product_2($x, $A)
<span class=hljs-meta >@btime</span> product_3($x, $A)
<span class=hljs-meta >@btime</span> product_1($x, $B)
<span class=hljs-meta >@btime</span> product_2($x, $B)
<span class=hljs-meta >@btime</span> product_3($x, $B)</code></pre> <p><code>product_1</code> and <code>product_3</code> are implemented in &quot;pure Julia&quot;, while <code>product_2</code> calls out to the BLAS library for both the matrix-vector multiply and the vector-vector dot product. I get</p> <pre><code class="julia hljs">julia&gt; <span class=hljs-meta >@btime</span> product_1($x, $A)
  <span class=hljs-number >3.662</span> μs (<span class=hljs-number >0</span> allocations: <span class=hljs-number >0</span> bytes)
<span class=hljs-number >508214.49429146934</span>

julia&gt; <span class=hljs-meta >@btime</span> product_2($x, $A)
  <span class=hljs-number >2.366</span> μs (<span class=hljs-number >1</span> allocation: <span class=hljs-number >1.77</span> KiB)
<span class=hljs-number >508214.49429146945</span>

julia&gt; <span class=hljs-meta >@btime</span> product_3($x, $A)
  <span class=hljs-number >5.368</span> μs (<span class=hljs-number >0</span> allocations: <span class=hljs-number >0</span> bytes)
<span class=hljs-number >508214.49429146847</span>

julia&gt; <span class=hljs-meta >@btime</span> product_1($x, $B)
  <span class=hljs-number >7.090</span> μs (<span class=hljs-number >0</span> allocations: <span class=hljs-number >0</span> bytes)
<span class=hljs-number >508214.49429146847</span>

julia&gt; <span class=hljs-meta >@btime</span> product_2($x, $B)
  <span class=hljs-number >1.734</span> μs (<span class=hljs-number >1</span> allocation: <span class=hljs-number >1.77</span> KiB)
<span class=hljs-number >508214.49429146945</span>

julia&gt; <span class=hljs-meta >@btime</span> product_3($x, $B)
  <span class=hljs-number >8.916</span> μs (<span class=hljs-number >0</span> allocations: <span class=hljs-number >0</span> bytes)
<span class=hljs-number >508214.49429146847</span>

julia&gt; versioninfo()
Julia Version <span class=hljs-number >1.10</span><span class=hljs-number >.0</span>-DEV<span class=hljs-number >.175</span>
Commit <span class=hljs-number >0</span>d469bd0f8* (<span class=hljs-number >2022</span>-<span class=hljs-number >12</span>-<span class=hljs-number >18</span> <span class=hljs-number >20</span>:<span class=hljs-number >11</span> UTC)
Platform Info:
  OS: Linux (x86_64-redhat-linux)
  CPU: <span class=hljs-number >36</span> × Intel(R) Core(TM) i9-<span class=hljs-number >10980</span>XE CPU @ <span class=hljs-number >3.00</span>GHz
  WORD_SIZE: <span class=hljs-number >64</span>
  LIBM: libopenlibm
  LLVM: libLLVM-<span class=hljs-number >14.0</span><span class=hljs-number >.6</span> (ORCJIT, cascadelake)
  Threads: <span class=hljs-number >36</span> on <span class=hljs-number >36</span> virtual cores</code></pre> <p>My CPU is cascadelake, an Intel Skylake-X clone feature AVX512 and 1MiB L2 cache/core. MKL is winning, especially for symmetric matrices, despite the fact we&#39;ve limited it to only a single thread, and that it needs to allocate and write memory. <code>using MKL</code> is encouraged for best performance when possible, the default library OpenBLAS is likely to be slower.</p> <p>Coming up second best will not do, especially when there&#39;s such an obvious deficit in <code>product_2</code> – the need to allocate and write memory.</p> <p>Asymptotically, the performance is limited by the rate at which we can loading memory from the matrix. Thus we should certainly see <code>Symmetric</code> winning, at least so long as we take advantage of the structure to avoid loading any elements more than once.</p> <p>Lets take a quick look using <a href="https://juliaperf.github.io/LIKWID.jl">LIKWID</a> to try and get a better idea of the performance. For convenience, I define</p> <pre><code class="julia hljs"><span class=hljs-keyword >using</span> LIKWID, DataFrames, PrettyTables
foreachf(f::F, N::<span class=hljs-built_in >Int</span>, arg1::A, args::<span class=hljs-built_in >Vararg</span>{<span class=hljs-built_in >Any</span>,K}) <span class=hljs-keyword >where</span> {F,A,K} = 
    foreach(_ -&gt; Base.donotdelete(f(arg1, args...)), <span class=hljs-number >1</span>:N)
	
<span class=hljs-keyword >function</span> filtered_print(metrics)
    subsetdict = <span class=hljs-built_in >Dict</span>( 
	    <span class=hljs-string >&quot;FLOPS_DP&quot;</span> =&gt; [<span class=hljs-string >&quot;Runtime (RDTSC) [s]&quot;</span>, <span class=hljs-string >&quot;Runtime unhalted [s]&quot;</span>, <span class=hljs-string >&quot;CPI&quot;</span>, <span class=hljs-string >&quot;DP [MFLOP/s]&quot;</span>, <span class=hljs-string >&quot;AVX512 DP [MFLOP/s]&quot;</span>, <span class=hljs-string >&quot;Packed [MUOPS/s]&quot;</span>, <span class=hljs-string >&quot;Scalar [MUOPS/s]&quot;</span>, <span class=hljs-string >&quot;Vectorization ratio&quot;</span>],
	    <span class=hljs-string >&quot;CYCLE_STALLS&quot;</span> =&gt; [<span class=hljs-string >&quot;Total execution stalls&quot;</span>, <span class=hljs-string >&quot;Stalls caused by L1D misses [%]&quot;</span>, <span class=hljs-string >&quot;Stalls caused by L2 misses [%]&quot;</span>, <span class=hljs-string >&quot;Execution stall rate [%]&quot;</span>, <span class=hljs-string >&quot;Stalls caused by L1D misses rate [%]&quot;</span>, <span class=hljs-string >&quot;Stalls caused by L2 misses rate [%]&quot;</span>, <span class=hljs-string >&quot;Stalls caused by memory loads rate [%]&quot;</span>],
	    <span class=hljs-string >&quot;CACHES&quot;</span> =&gt; [<span class=hljs-string >&quot;L2 to L1 load bandwidth [MBytes/s]&quot;</span>, <span class=hljs-string >&quot;L2 to L1 load data volume [GBytes]&quot;</span>, <span class=hljs-string >&quot;L1 to L2 evict bandwidth [MBytes/s]&quot;</span>, <span class=hljs-string >&quot;L1 to L2 evict data volume [GBytes]&quot;</span>, <span class=hljs-string >&quot;L1 to/from L2 bandwidth [MBytes/s]&quot;</span>, <span class=hljs-string >&quot;L1 to/from L2 data volume [GBytes]&quot;</span>],
        <span class=hljs-string >&quot;BRANCH&quot;</span> =&gt; [<span class=hljs-string >&quot;Branch misprediction rate&quot;</span>, <span class=hljs-string >&quot;Instructions per branch&quot;</span>]
	)
	ms = <span class=hljs-built_in >String</span>[];
	t1vs = <span class=hljs-built_in >Float64</span>[];
	<span class=hljs-keyword >for</span> (k,vs) = metrics
	    v = first(vs) <span class=hljs-comment ># extract thread 1 only; FIXME in case of multithreading!</span>
		submetrics = subsetdict[k]
		append!(ms, submetrics)
		<span class=hljs-keyword >for</span> m = submetrics
		    push!(t1vs, v[m])
		<span class=hljs-keyword >end</span>
	<span class=hljs-keyword >end</span>
	pretty_table(DataFrame(Metric = ms, <span class=hljs-string >var&quot;Thread 1&quot;</span> = t1vs))
<span class=hljs-keyword >end</span></code></pre> <p><code>foreachf</code> is so that I can run code many times. Here, I will keep <code>N &#61; 1_000_000</code> across profiles to keep results consistent. <code>filtered_print</code> is to give a more concise output. Let&#39;s compare <code>product_1</code> with <code>product_3</code> using the dense matrix; I manually filtered the results:</p> <pre><code class="julia hljs">julia&gt; met, evt = <span class=hljs-meta >@perfmon</span> (<span class=hljs-string >&quot;FLOPS_DP&quot;</span>, <span class=hljs-string >&quot;CYCLE_STALLS&quot;</span>, <span class=hljs-string >&quot;CACHES&quot;</span>, <span class=hljs-string >&quot;BRANCH&quot;</span>) foreachf(product_1, <span class=hljs-number >1_000_000</span>, x, A);

julia filtered_print(met);
┌────────────────────────────────────────┬────────────┐
│                                 Metric │   Thread <span class=hljs-number >1</span> │
│                                 <span class=hljs-built_in >String</span> │    <span class=hljs-built_in >Float64</span> │
├────────────────────────────────────────┼────────────┤
│                    Runtime (RDTSC) [s] │    <span class=hljs-number >4.31409</span> │
│                   Runtime unhalted [s] │    <span class=hljs-number >4.09009</span> │
│                                    CPI │    <span class=hljs-number >0.50087</span> │
│                           DP [MFLOP/s] │    <span class=hljs-number >14603.8</span> │
│                    AVX512 DP [MFLOP/s] │    <span class=hljs-number >13769.3</span> │
│                       Packed [MUOPS/s] │     <span class=hljs-number >1760.9</span> │
│                       Scalar [MUOPS/s] │    <span class=hljs-number >754.986</span> │
│                    Vectorization ratio │    <span class=hljs-number >69.9913</span> │
│                 Total execution stalls │  <span class=hljs-number >2.76645e9</span> │
│        Stalls caused by L1D misses [%] │    <span class=hljs-number >83.0887</span> │
│         Stalls caused by L2 misses [%] │   <span class=hljs-number >0.625892</span> │
│               Execution stall rate [%] │    <span class=hljs-number >22.5896</span> │
│   Stalls caused by L1D misses rate [%] │    <span class=hljs-number >18.7694</span> │
│    Stalls caused by L2 misses rate [%] │   <span class=hljs-number >0.141387</span> │
│ Stalls caused by memory loads rate [%] │    <span class=hljs-number >27.0086</span> │
│     L2 to L1 load bandwidth [MBytes/s] │    <span class=hljs-number >64062.1</span> │
│     L2 to L1 load data volume [GBytes] │    <span class=hljs-number >275.821</span> │
│    L1 to L2 evict bandwidth [MBytes/s] │    <span class=hljs-number >77.0877</span> │
│    L1 to L2 evict data volume [GBytes] │   <span class=hljs-number >0.331903</span> │
│     L1 to/from L2 bandwidth [MBytes/s] │    <span class=hljs-number >64139.2</span> │
│     L1 to/from L2 data volume [GBytes] │    <span class=hljs-number >276.153</span> │
│              Branch misprediction rate │ <span class=hljs-number >6.67933e-5</span> │
│                Instructions per branch │    <span class=hljs-number >7.20618</span> │
└────────────────────────────────────────┴────────────┘

julia&gt; m, e = <span class=hljs-meta >@perfmon</span> (<span class=hljs-string >&quot;FLOPS_DP&quot;</span>, <span class=hljs-string >&quot;CYCLE_STALLS&quot;</span>, <span class=hljs-string >&quot;CACHES&quot;</span>, <span class=hljs-string >&quot;BRANCH&quot;</span>) foreachf(product_3, <span class=hljs-number >1_000_000</span>, x, A);

julia filtered_print(m);
┌────────────────────────────────────────┬────────────┐
│                                 Metric │   Thread <span class=hljs-number >1</span> │
│                                 <span class=hljs-built_in >String</span> │    <span class=hljs-built_in >Float64</span> │
├────────────────────────────────────────┼────────────┤
│                    Runtime (RDTSC) [s] │    <span class=hljs-number >5.50317</span> │
│                   Runtime unhalted [s] │    <span class=hljs-number >5.21599</span> │
│                                    CPI │   <span class=hljs-number >0.607209</span> │
│                           DP [MFLOP/s] │    <span class=hljs-number >8882.12</span> │
│                    AVX512 DP [MFLOP/s] │    <span class=hljs-number >7275.45</span> │
│                       Packed [MUOPS/s] │    <span class=hljs-number >935.599</span> │
│                       Scalar [MUOPS/s] │    <span class=hljs-number >1554.33</span> │
│                    Vectorization ratio │    <span class=hljs-number >37.5753</span> │
│                 Total execution stalls │  <span class=hljs-number >3.94969e9</span> │
│        Stalls caused by L1D misses [%] │    <span class=hljs-number >41.0844</span> │
│         Stalls caused by L2 misses [%] │   <span class=hljs-number >0.956054</span> │
│               Execution stall rate [%] │    <span class=hljs-number >25.1506</span> │
│   Stalls caused by L1D misses rate [%] │     <span class=hljs-number >10.333</span> │
│    Stalls caused by L2 misses rate [%] │   <span class=hljs-number >0.240453</span> │
│ Stalls caused by memory loads rate [%] │    <span class=hljs-number >26.4968</span> │
│     L2 to L1 load bandwidth [MBytes/s] │    <span class=hljs-number >30344.9</span> │
│     L2 to L1 load data volume [GBytes] │    <span class=hljs-number >167.261</span> │
│    L1 to L2 evict bandwidth [MBytes/s] │    <span class=hljs-number >146.758</span> │
│    L1 to L2 evict data volume [GBytes] │   <span class=hljs-number >0.808929</span> │
│     L1 to/from L2 bandwidth [MBytes/s] │    <span class=hljs-number >30491.7</span> │
│     L1 to/from L2 data volume [GBytes] │     <span class=hljs-number >168.07</span> │
│              Branch misprediction rate │ <span class=hljs-number >0.00199066</span> │
│                Instructions per branch │    <span class=hljs-number >6.42476</span> │
└────────────────────────────────────────┴────────────┘</code></pre> <p>That that <code>product_3</code> was executing over <code>50&#37;</code> more scalar <code>MUOPS/s</code> than packed. Each scalar <code>MUOP</code> doesn&#39;t contribute nearly as many FLOPS as packed one, so the total <code>DP &#91;MFLOP/s&#93;</code> still wasn&#39;t much higher than the <code>AVX512</code>-only value. <code>product_1</code> did much better in this respect. It also had more instructions per branch. However, it did require much higher L2 to L1 load data, and thus also higher bandwidth, as we expected because it didn&#39;t take advantage of symmetry.</p> <p>CPI is cycles per instruction, the higher the value, the more clock cycles were required per instruction. We see that the execution stall rate was higher for <code>product_3</code>.</p> <p>For comparison, this is the symmetric <code>product_2</code>:</p> <pre><code class="julia hljs">┌────────────────────────────────────────┬─────────────┐
│                                 Metric │    Thread <span class=hljs-number >1</span> │
│                                 <span class=hljs-built_in >String</span> │     <span class=hljs-built_in >Float64</span> │
├────────────────────────────────────────┼─────────────┤
│                    Runtime (RDTSC) [s] │     <span class=hljs-number >2.10946</span> │
│                   Runtime unhalted [s] │     <span class=hljs-number >1.95101</span> │
│                                    CPI │     <span class=hljs-number >0.41146</span> │
│                           DP [MFLOP/s] │     <span class=hljs-number >30664.5</span> │
│                    AVX512 DP [MFLOP/s] │     <span class=hljs-number >30663.7</span> │
│                       Packed [MUOPS/s] │     <span class=hljs-number >3833.36</span> │
│                       Scalar [MUOPS/s] │         <span class=hljs-number >0.0</span> │
│                    Vectorization ratio │       <span class=hljs-number >100.0</span> │
│                 Total execution stalls │   <span class=hljs-number >7.93344e8</span> │
│        Stalls caused by L1D misses [%] │     <span class=hljs-number >73.9433</span> │
│         Stalls caused by L2 misses [%] │     <span class=hljs-number >13.8556</span> │
│               Execution stall rate [%] │     <span class=hljs-number >13.5926</span> │
│   Stalls caused by L1D misses rate [%] │     <span class=hljs-number >10.0508</span> │
│    Stalls caused by L2 misses rate [%] │     <span class=hljs-number >1.88334</span> │
│ Stalls caused by memory loads rate [%] │     <span class=hljs-number >14.0704</span> │
│     L2 to L1 load bandwidth [MBytes/s] │     <span class=hljs-number >74542.3</span> │
│     L2 to L1 load data volume [GBytes] │     <span class=hljs-number >156.499</span> │
│    L1 to L2 evict bandwidth [MBytes/s] │     <span class=hljs-number >1823.74</span> │
│    L1 to L2 evict data volume [GBytes] │     <span class=hljs-number >3.82889</span> │
│     L1 to/from L2 bandwidth [MBytes/s] │     <span class=hljs-number >76366.0</span> │
│     L1 to/from L2 data volume [GBytes] │     <span class=hljs-number >160.328</span> │
│              Branch misprediction rate │ <span class=hljs-number >0.000151162</span> │
│                Instructions per branch │     <span class=hljs-number >19.2526</span> │
└────────────────────────────────────────┴─────────────┘</code></pre> <p>Note the vectorization ratio of 100.0; only slightly more 512b instructions executed, and zero scalar. The CPI was also low. <code>product_2</code> hit over 30 GFLOPS &#40;30664.5 MFLOPS/s&#41;. We see a much better use of execution resources &#40;i.e. vectorization&#41;, and far fewer branches. The execution stall rate and CPI were lower.</p> <p>While LoopModels will be able to handle symmetry and arbitrary affine loop nests, LoopVectorization.jl is unfortunately limited to only rectangular loop nests, thus it cannot handle the symmetric case. I also plan on adding cache tiling to LoopModels, but this is also something LoopVectorization.jl does not support, so performance likely will not scale to larger sizes, nor do we consider things like alignment. But a 200x200 matrix fits neatly in cache, and has column sizes that are an integer multiple of 64 bytes, so none of this matters here. As a result, we had </p> <pre><code class="julia hljs"><span class=hljs-keyword >function</span> dotturbo(x, A)
    s = zero(promote_type(eltype(x), eltype(A)))
    <span class=hljs-meta >@turbo</span> <span class=hljs-keyword >for</span> n ∈ axes(A, <span class=hljs-number >2</span>)
        t = zero(s)
        <span class=hljs-keyword >for</span> m ∈ axes(A, <span class=hljs-number >1</span>)
            t += x[m] * A[m, n]
        <span class=hljs-keyword >end</span>
        s += t * x[n]
    <span class=hljs-keyword >end</span>
    s
<span class=hljs-keyword >end</span></code></pre> <p>Note that we manually implemented an optimization also used in <code>LinearAlgebra.dot</code>: we hoisted the multiplication by <code>x&#91;n&#93;</code> out of the loop. It&#39;s also my intention to automate this, but <code>LoopVectorization.jl</code>&#39;s transforms are fairly limited, and my performance development time has of course moved elsewhere.</p> <p>I get</p> <pre><code class="julia hljs">julia&gt; <span class=hljs-meta >@btime</span> dotturbo($x, $A)
  <span class=hljs-number >1.875</span> μs (<span class=hljs-number >0</span> allocations: <span class=hljs-number >0</span> bytes)
<span class=hljs-number >508214.49429146945</span></code></pre> <p>At least we&#39;re now winning the dense case. Thanks to the occasional GC activity from memory allocations, we&#39;re not too far behind the <code>Symmetric</code> case in average performance:</p> <pre><code class="julia hljs">julia&gt; <span class=hljs-meta >@benchmark</span> dotturbo($x, $A)
BenchmarkTools.Trial: <span class=hljs-number >10000</span> samples with <span class=hljs-number >10</span> evaluations.
 Range (min … max):  <span class=hljs-number >1.869</span> μs …  <span class=hljs-number >6.652</span> μs  ┊ GC (min … max): <span class=hljs-number >0.00</span>% … <span class=hljs-number >0.00</span>%
 Time  (median):     <span class=hljs-number >1.887</span> μs              ┊ GC (median):    <span class=hljs-number >0.00</span>%
 Time  (mean ± σ):   <span class=hljs-number >1.892</span> μs ± <span class=hljs-number >56.790</span> ns  ┊ GC (mean ± σ):  <span class=hljs-number >0.00</span>% ± <span class=hljs-number >0.00</span>%

      ▄█▇▅▃
  ▂▂▃▆██████▅▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▂▁▂▂▁▂▂▁▁▁▁▂▁▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂ ▃
  <span class=hljs-number >1.87</span> μs        Histogram: frequency by time        <span class=hljs-number >2.03</span> μs &lt;

 Memory estimate: <span class=hljs-number >0</span> bytes, allocs estimate: <span class=hljs-number >0.</span>

julia&gt; <span class=hljs-meta >@benchmark</span> product_2($x, $B)
BenchmarkTools.Trial: <span class=hljs-number >10000</span> samples with <span class=hljs-number >10</span> evaluations.
 Range (min … max):  <span class=hljs-number >1.733</span> μs … <span class=hljs-number >107.171</span> μs  ┊ GC (min … max): <span class=hljs-number >0.00</span>% … <span class=hljs-number >93.21</span>%
 Time  (median):     <span class=hljs-number >1.768</span> μs               ┊ GC (median):    <span class=hljs-number >0.00</span>%
 Time  (mean ± σ):   <span class=hljs-number >1.843</span> μs ±   <span class=hljs-number >1.972</span> μs  ┊ GC (mean ± σ):  <span class=hljs-number >2.04</span>% ±  <span class=hljs-number >1.88</span>%

    ▁█▇▁
  ▁▃████▅▃▃▂▂▂▂▂▂▃▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁ ▂
  <span class=hljs-number >1.73</span> μs         Histogram: frequency by time        <span class=hljs-number >2.12</span> μs &lt;

 Memory estimate: <span class=hljs-number >1.77</span> KiB, allocs estimate: <span class=hljs-number >1.</span></code></pre> <p>1.892 vs 1.843 microseconds.</p> <p>The LIKWID results of <code>dotturbo</code>:</p> <pre><code class="julia hljs">┌────────────────────────────────────────┬────────────┐
│                                 Metric │   Thread <span class=hljs-number >1</span> │
│                                 <span class=hljs-built_in >String</span> │    <span class=hljs-built_in >Float64</span> │
├────────────────────────────────────────┼────────────┤
│                    Runtime (RDTSC) [s] │    <span class=hljs-number >2.03067</span> │
│                   Runtime unhalted [s] │    <span class=hljs-number >1.92501</span> │
│                                    CPI │   <span class=hljs-number >0.620848</span> │
│                           DP [MFLOP/s] │    <span class=hljs-number >29055.0</span> │
│                    AVX512 DP [MFLOP/s] │    <span class=hljs-number >28545.1</span> │
│                       Packed [MUOPS/s] │    <span class=hljs-number >3769.91</span> │
│                       Scalar [MUOPS/s] │   <span class=hljs-number >0.844273</span> │
│                    Vectorization ratio │    <span class=hljs-number >99.9776</span> │
│                 Total execution stalls │  <span class=hljs-number >9.37384e8</span> │
│        Stalls caused by L1D misses [%] │    <span class=hljs-number >116.368</span> │
│         Stalls caused by L2 misses [%] │    <span class=hljs-number >1.49769</span> │
│               Execution stall rate [%] │    <span class=hljs-number >16.2874</span> │
│   Stalls caused by L1D misses rate [%] │    <span class=hljs-number >18.9533</span> │
│    Stalls caused by L2 misses rate [%] │   <span class=hljs-number >0.243935</span> │
│ Stalls caused by memory loads rate [%] │    <span class=hljs-number >19.4328</span> │
│     L2 to L1 load bandwidth [MBytes/s] │  <span class=hljs-number >1.37391e5</span> │
│     L2 to L1 load data volume [GBytes] │    <span class=hljs-number >277.845</span> │
│    L1 to L2 evict bandwidth [MBytes/s] │    <span class=hljs-number >406.024</span> │
│    L1 to L2 evict data volume [GBytes] │     <span class=hljs-number >0.8211</span> │
│     L1 to/from L2 bandwidth [MBytes/s] │  <span class=hljs-number >1.37797e5</span> │
│     L1 to/from L2 data volume [GBytes] │    <span class=hljs-number >278.666</span> │
│              Branch misprediction rate │ <span class=hljs-number >9.64224e-5</span> │
│                Instructions per branch │    <span class=hljs-number >12.6511</span> │
└────────────────────────────────────────┴────────────┘</code></pre> <p>Timing reported here is again similar, but CPI is much higher; seems despite being dense we nonetheless needed fewer instructions, which isn&#39;t surprising as <a href="https://github.com/JuliaSIMD/LoopVectorization.jl">LoopVectorization.jl</a>&#39;s objective function tries to minimize MUOP count. Being dense, the bandwidth needs were higher.</p> <p>Attaining comparable performance here smells like blood in the water <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>−</mo></mrow><annotation encoding="application/x-tex">-</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.66666em;vertical-align:-0.08333em;"></span><span class=mord >−</span></span></span></span> lets take advantage of symmetry to win this benchmark.</p> <p>Lets start with <code>product_3</code>, and apply one transform at a time to discuss it&#39;s problems. First, we can hoist a lot of arithmetic.</p> <pre><code class="julia hljs"><span class=hljs-keyword >function</span> product_4(x, _M)
    n = length(x)
    result_diag = zero(eltype(x))
    result_supd = zero(eltype(x))
    M = _M <span class=hljs-keyword >isa</span> Symmetric ? parent(_M) : _M
    Base.require_one_based_indexing(x)
    Base.require_one_based_indexing(M)
    <span class=hljs-meta >@inbounds</span> <span class=hljs-keyword >for</span> i = <span class=hljs-number >1</span>:n
        result_diag += x[i]^<span class=hljs-number >2</span> * M[i, i]
        result_innr = zero(eltype(x))
        <span class=hljs-meta >@simd</span> <span class=hljs-keyword >for</span> j = <span class=hljs-number >1</span> : i - <span class=hljs-number >1</span>
            result_innr += x[j] * M[j, i]
        <span class=hljs-keyword >end</span>
        result_supd += x[i]*result_innr
    <span class=hljs-keyword >end</span>
    <span class=hljs-keyword >return</span> <span class=hljs-number >2</span>result_supd + result_diag
<span class=hljs-keyword >end</span></code></pre> <p>yielding</p> <pre><code class="julia hljs">julia&gt; <span class=hljs-meta >@btime</span> product_4($x, $B)
  <span class=hljs-number >3.977</span> μs (<span class=hljs-number >0</span> allocations: <span class=hljs-number >0</span> bytes)
<span class=hljs-number >508214.49429146934</span></code></pre> <p>Better, now we&#39;re more in line with <code>product_1</code>. If our math is slow, maybe we just need to ask the compiler to make it fast?</p> <pre><code class="julia hljs"><span class=hljs-meta >@fastmath</span> <span class=hljs-keyword >function</span> product_5(x, _M) <span class=hljs-comment ># only change is `@fastmath`</span>
    n = length(x)
    result_diag = zero(eltype(x))
    result_supd = zero(eltype(x))
    M = _M <span class=hljs-keyword >isa</span> Symmetric ? parent(_M) : _M
    Base.require_one_based_indexing(x)
    Base.require_one_based_indexing(M)
    <span class=hljs-meta >@inbounds</span> <span class=hljs-keyword >for</span> i = <span class=hljs-number >1</span>:n
        result_diag += x[i]^<span class=hljs-number >2</span> * M[i, i]
        result_innr = zero(eltype(x))
        <span class=hljs-meta >@simd</span> <span class=hljs-keyword >for</span> j = <span class=hljs-number >1</span> : i - <span class=hljs-number >1</span>
            result_innr += x[j] * M[j, i]
        <span class=hljs-keyword >end</span>
        result_supd += x[i]*result_innr
    <span class=hljs-keyword >end</span>
    <span class=hljs-keyword >return</span> <span class=hljs-number >2</span>result_supd + result_diag
<span class=hljs-keyword >end</span></code></pre> <p>so we&#39;re now beating <code>product_1</code> with dense arrays:</p> <pre><code class="julia hljs">julia&gt; <span class=hljs-meta >@btime</span> product_5($x, $B)
  <span class=hljs-number >3.503</span> μs (<span class=hljs-number >0</span> allocations: <span class=hljs-number >0</span> bytes)
<span class=hljs-number >508214.49429146934</span></code></pre> <p>But we&#39;re still a far cry from <code>@turbo</code>. Unfortunately, because <code>LoopVectorization.jl</code> only supports rectangular loops, we&#39;re limited to applying it to the inner-most loop, hamstringing it:</p> <pre><code class="julia hljs"><span class=hljs-meta >@fastmath</span> <span class=hljs-keyword >function</span> product_6(x, _M) <span class=hljs-comment ># only change is `@fastmath`</span>
    n = length(x)
    n == <span class=hljs-number >0</span> &amp;&amp; <span class=hljs-keyword >return</span> zero(eltype(x))
    M = _M <span class=hljs-keyword >isa</span> Symmetric ? parent(_M) : _M
    Base.require_one_based_indexing(x)
    Base.require_one_based_indexing(M)
    result_diag = x[<span class=hljs-number >1</span>]^<span class=hljs-number >2</span> * M[<span class=hljs-number >1</span>, <span class=hljs-number >1</span>]
    result_supd = zero(eltype(x))
    <span class=hljs-comment ># `@turbo` doesn&#x27;t support length-0 iteration</span>
    <span class=hljs-comment ># so we need to make sure length(1:i-1) &gt; 0</span>
    <span class=hljs-meta >@inbounds</span> <span class=hljs-keyword >for</span> i = <span class=hljs-number >2</span>:n 
        result_diag += x[i]^<span class=hljs-number >2</span> * M[i, i]
        result_innr = zero(eltype(x))
        <span class=hljs-meta >@turbo</span> <span class=hljs-keyword >for</span> j = <span class=hljs-number >1</span> : i - <span class=hljs-number >1</span>
            result_innr += x[j] * M[j, i]
        <span class=hljs-keyword >end</span>
        result_supd += x[i]*result_innr
    <span class=hljs-keyword >end</span>
    <span class=hljs-keyword >return</span> <span class=hljs-number >2</span>result_supd + result_diag
<span class=hljs-keyword >end</span></code></pre> <p>yet</p> <pre><code class="julia hljs">julia&gt; <span class=hljs-meta >@btime</span> product_6($x, $B)
  <span class=hljs-number >1.795</span> μs (<span class=hljs-number >0</span> allocations: <span class=hljs-number >0</span> bytes)
<span class=hljs-number >508214.4942914694</span>

julia&gt; <span class=hljs-meta >@benchmark</span> product_6($x, $B)
BenchmarkTools.Trial: <span class=hljs-number >10000</span> samples with <span class=hljs-number >10</span> evaluations.
 Range (min … max):  <span class=hljs-number >1.663</span> μs …  <span class=hljs-number >5.431</span> μs  ┊ GC (min … max): <span class=hljs-number >0.00</span>% … <span class=hljs-number >0.00</span>%
 Time  (median):     <span class=hljs-number >1.680</span> μs              ┊ GC (median):    <span class=hljs-number >0.00</span>%
 Time  (mean ± σ):   <span class=hljs-number >1.717</span> μs ± <span class=hljs-number >73.691</span> ns  ┊ GC (mean ± σ):  <span class=hljs-number >0.00</span>% ± <span class=hljs-number >0.00</span>%

   ▂▇█▅▁                               ▁
  ▃█████▅▅▃▂▂▂▂▂▂▁▁▁▂▁▁▂▁▁▂▁▂▂▂▁▁▁▁▂▂▂▄█▇▆▅▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂ ▃
  <span class=hljs-number >1.66</span> μs        Histogram: frequency by time        <span class=hljs-number >1.88</span> μs &lt;

 Memory estimate: <span class=hljs-number >0</span> bytes, allocs estimate: <span class=hljs-number >0.</span></code></pre> <p>I&#39;m not sure why the minimum time from <code>@btime</code> was so much higher than the mean time from <code>@benchmark</code>.</p> <p>But we&#39;re now at least in clear contention with MKL&#39;s <code>symv&#33;</code>&#43;<code>dot</code>. So, if we could only apply <code>@turbo</code> to the inner loop, why did it help so much? LLVM is really bad at producing code for architectures with big vectors, and AVX512 in particular. On a Zen3 CPU with AVX2, I got</p> <pre><code class="julia hljs">julia&gt; <span class=hljs-meta >@btime</span> product_5($x, $B)
  <span class=hljs-number >2.537</span> μs (<span class=hljs-number >0</span> allocations: <span class=hljs-number >0</span> bytes)
<span class=hljs-number >502848.6107780409</span>

julia&gt; <span class=hljs-meta >@btime</span> product_6($x, $B)
  <span class=hljs-number >2.063</span> μs (<span class=hljs-number >0</span> allocations: <span class=hljs-number >0</span> bytes)
<span class=hljs-number >502848.61077804095</span></code></pre> <p>while on an Apple M1, I got</p> <pre><code class="julia hljs">julia&gt; <span class=hljs-meta >@btime</span> product_5($x, $B)
  <span class=hljs-number >3.604</span> μs (<span class=hljs-number >0</span> allocations: <span class=hljs-number >0</span> bytes)
<span class=hljs-number >580770.6876433745</span>

julia&gt; <span class=hljs-meta >@btime</span> product_6($x, $B)
  <span class=hljs-number >3.521</span> μs (<span class=hljs-number >0</span> allocations: <span class=hljs-number >0</span> bytes)
<span class=hljs-number >580770.6876433745</span></code></pre> <p>so the performance advantage decreases as the vector width decreases. This is mostly because LLVM doesn&#39;t handle remainders efficiently. The larger the vectors, the larger the remainders on average, the worse LLVM&#39;s performance.</p> <p>So, what&#39;s left, what&#39;s missing? What would <code>@turbo</code> on an outerloop do differently? For one thing, reducing vectors to scalars is expensive, so <code>@turbo</code> will only do so once at the end, while our code is doing so on every iteration of the outer loop. How can we avoid doing so?</p> <p>We can tell <code>@turbo</code> we want to accumulate into a SIMD vector instead of a scalar by defining our accumulator to be a <code>VectorizationBase.Vec</code> instead of a scalar. Then, we just have to accumulate the vector into a scalar ourselves before returning the value:</p> <pre><code class="julia hljs"><span class=hljs-keyword >using</span> VectorizationBase
<span class=hljs-meta >@fastmath</span> <span class=hljs-keyword >function</span> product_7(x, _M) <span class=hljs-comment ># only change is `@fastmath`</span>
    n = length(x)
    T = eltype(x)
    n == <span class=hljs-number >0</span> &amp;&amp; <span class=hljs-keyword >return</span> zero(T)
    M = _M <span class=hljs-keyword >isa</span> Symmetric ? parent(_M) : _M
    Base.require_one_based_indexing(x)
    Base.require_one_based_indexing(M)
    result_diag = Vec(zero(T))
    <span class=hljs-meta >@turbo</span> <span class=hljs-keyword >for</span> i = <span class=hljs-number >1</span>:n
        result_diag += x[i]^<span class=hljs-number >2</span> * M[i, i]
    <span class=hljs-keyword >end</span>
    result_supd = Vec(zero(T))
    <span class=hljs-comment ># `@turbo` doesn&#x27;t support length-0 iteration</span>
    <span class=hljs-comment ># so we need to make sure length(1:i-1) &gt; 0</span>
    <span class=hljs-meta >@inbounds</span> <span class=hljs-keyword >for</span> i = <span class=hljs-number >2</span>:n 
        result_innr = Vec(zero(T))
        <span class=hljs-meta >@turbo</span> <span class=hljs-keyword >for</span> j = <span class=hljs-number >1</span> : i - <span class=hljs-number >1</span>
            result_innr += x[j] * M[j, i]
        <span class=hljs-keyword >end</span>
        result_supd += x[i]*result_innr
    <span class=hljs-keyword >end</span>
    <span class=hljs-keyword >return</span> VectorizationBase.vsum(<span class=hljs-number >2</span>result_supd + result_diag)
<span class=hljs-keyword >end</span></code></pre> <p>Now I get:</p> <pre><code class="julia hljs">julia&gt; <span class=hljs-meta >@btime</span> product_7($x, $B)
  <span class=hljs-number >1.354</span> μs (<span class=hljs-number >0</span> allocations: <span class=hljs-number >0</span> bytes)
<span class=hljs-number >508214.4942914695</span></code></pre> <p>Well ahead of any other implementation. The CPI of LIKWID results look quite good, especially <code>CPI</code>:</p> <pre><code class="julia hljs">┌────────────────────────────────────────┬─────────────┐
│                                 Metric │    Thread <span class=hljs-number >1</span> │
│                                 <span class=hljs-built_in >String</span> │     <span class=hljs-built_in >Float64</span> │
├────────────────────────────────────────┼─────────────┤
│                    Runtime (RDTSC) [s] │     <span class=hljs-number >1.59119</span> │
│                   Runtime unhalted [s] │     <span class=hljs-number >1.50887</span> │
│                                    CPI │    <span class=hljs-number >0.321119</span> │
│                           DP [MFLOP/s] │     <span class=hljs-number >22122.9</span> │
│                    AVX512 DP [MFLOP/s] │     <span class=hljs-number >22121.3</span> │
│                       Packed [MUOPS/s] │      <span class=hljs-number >2765.7</span> │
│                       Scalar [MUOPS/s] │    <span class=hljs-number >0.538865</span> │
│                    Vectorization ratio │     <span class=hljs-number >99.9805</span> │
│                 Total execution stalls │   <span class=hljs-number >4.70885e8</span> │
│        Stalls caused by L1D misses [%] │     <span class=hljs-number >98.6231</span> │
│         Stalls caused by L2 misses [%] │     <span class=hljs-number >3.33533</span> │
│               Execution stall rate [%] │     <span class=hljs-number >10.3786</span> │
│   Stalls caused by L1D misses rate [%] │     <span class=hljs-number >10.2357</span> │
│    Stalls caused by L2 misses rate [%] │     <span class=hljs-number >0.34616</span> │
│ Stalls caused by memory loads rate [%] │     <span class=hljs-number >11.8953</span> │
│     L2 to L1 load bandwidth [MBytes/s] │     <span class=hljs-number >99520.2</span> │
│     L2 to L1 load data volume [GBytes] │     <span class=hljs-number >158.482</span> │
│    L1 to L2 evict bandwidth [MBytes/s] │     <span class=hljs-number >512.454</span> │
│    L1 to L2 evict data volume [GBytes] │    <span class=hljs-number >0.816064</span> │
│     L1 to/from L2 bandwidth [MBytes/s] │   <span class=hljs-number >1.00033e5</span> │
│     L1 to/from L2 data volume [GBytes] │     <span class=hljs-number >159.298</span> │
│              Branch misprediction rate │ <span class=hljs-number >0.000174263</span> │
│                Instructions per branch │     <span class=hljs-number >9.08776</span> │
└────────────────────────────────────────┴─────────────┘</code></pre> <p>With a CPI of <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>&lt;</mo><mfrac><mn>1</mn><mn>3</mn></mfrac></mrow><annotation encoding="application/x-tex">&lt;\frac{1}{3}</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.5782em;vertical-align:-0.0391em;"></span><span class=mrel >&lt;</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span></span><span class=base ><span class=strut  style="height:1.190108em;vertical-align:-0.345em;"></span><span class=mord ><span class="mopen nulldelimiter"></span><span class=mfrac ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.845108em;"><span style="top:-2.6550000000000002em;"><span class=pstrut  style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">3</span></span></span></span><span style="top:-3.23em;"><span class=pstrut  style="height:3em;"></span><span class=frac-line  style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class=pstrut  style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span>, we averaged over 3 instructions per clock cycle&#33; Our vectorization ratio was also excellent, of course.</p> <p>Now that we have the fastest time, are we done?</p> <p>No, as hinted above there&#39;s another important optimization <code>@turbo</code> applies to the dense case. <code>@turbo</code> cuts down on the <code>x&#91;j&#93;</code> reloads in the inner <code>j</code> loop by unrolling the outer <code>i</code> loop. That is, if we unroll <code>M&#91;j,i&#93;</code> by 8, we can reuse an <code>x&#91;j&#93;</code> load 8 times before discarding it and moving on to the next inner loop iteration. In this way, we need <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mn>1</mn><mn>8</mn></mfrac></mrow><annotation encoding="application/x-tex">\frac{1}{8}</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:1.190108em;vertical-align:-0.345em;"></span><span class=mord ><span class="mopen nulldelimiter"></span><span class=mfrac ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.845108em;"><span style="top:-2.6550000000000002em;"><span class=pstrut  style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">8</span></span></span></span><span style="top:-3.23em;"><span class=pstrut  style="height:3em;"></span><span class=frac-line  style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class=pstrut  style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span> as many loads from <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">x</span></span></span></span> in the inner loop.</p> <pre><code class="julia hljs"><span class=hljs-keyword >function</span> product_8(x, _M)
    N = length(x)
    T = eltype(x)
    N == <span class=hljs-number >0</span> &amp;&amp; <span class=hljs-keyword >return</span> zero(T)
    M = _M <span class=hljs-keyword >isa</span> Symmetric ? parent(_M) : _M
    Base.require_one_based_indexing(x)
    Base.require_one_based_indexing(M)
    <span class=hljs-comment ># we unroll the outer loop by 8</span>
    remainder = N &amp; <span class=hljs-number >7</span>
    n = remainder
    <span class=hljs-keyword >if</span> n != N <span class=hljs-comment ># guard</span>
        <span class=hljs-comment ># 8 accumulators (for the outer loop)</span>
        Base.Cartesian.<span class=hljs-meta >@nexprs</span> <span class=hljs-number >4</span> i -&gt; acc_i = Vec(zero(T))
        <span class=hljs-keyword >while</span> <span class=hljs-literal >true</span>
            Base.Cartesian.<span class=hljs-meta >@nexprs</span> <span class=hljs-number >8</span> i -&gt; a_i = Vec(zero(T))
            <span class=hljs-comment ># iterations i = n+1:n+8</span>
            <span class=hljs-keyword >if</span> n != <span class=hljs-number >0</span>
                <span class=hljs-comment ># we&#x27;ll loop normally up through n</span>
                <span class=hljs-meta >@turbo</span> <span class=hljs-keyword >for</span> j = <span class=hljs-number >1</span>:n
                    Base.Cartesian.<span class=hljs-meta >@nexprs</span> <span class=hljs-number >8</span> i -&gt; <span class=hljs-keyword >begin</span>
                        a_i += x[j] * M[j,i+n]
                    <span class=hljs-keyword >end</span>
                <span class=hljs-keyword >end</span>
            <span class=hljs-keyword >end</span>
            <span class=hljs-comment ># 8x8 diagonal block</span>
            <span class=hljs-meta >@turbo</span> <span class=hljs-keyword >for</span> j = <span class=hljs-number >1</span>:<span class=hljs-number >8</span>
                Base.Cartesian.<span class=hljs-meta >@nexprs</span> <span class=hljs-number >8</span> i -&gt; <span class=hljs-keyword >begin</span>
                    mask_i = (j&lt;i) + <span class=hljs-number >0.5</span>*(j==i)
                    a_i += x[j+n] * (M[j+n,i+n] * mask_i)
                <span class=hljs-keyword >end</span>
            <span class=hljs-keyword >end</span>
            Base.Cartesian.<span class=hljs-meta >@nexprs</span> <span class=hljs-number >4</span> i -&gt; acc_i += x[i+n]*a_i
            Base.Cartesian.<span class=hljs-meta >@nexprs</span> <span class=hljs-number >4</span> i -&gt; acc_i += x[<span class=hljs-number >4</span>+i+n]*a_{<span class=hljs-number >4</span>+i}
            n += <span class=hljs-number >8</span>
            n == N &amp;&amp; <span class=hljs-keyword >break</span>
        <span class=hljs-keyword >end</span> <span class=hljs-comment ># while true</span>
        acc_1 += acc_3
        acc_2 += acc_4
        acc_1 += acc_2
        ret = <span class=hljs-number >2</span>*VectorizationBase.vsum(acc_1)
        remainder == <span class=hljs-number >0</span> &amp;&amp; <span class=hljs-keyword >return</span> ret
    <span class=hljs-keyword >else</span>
        ret = zero(T)
    <span class=hljs-keyword >end</span>
    <span class=hljs-comment ># we know remainder != 0, because N == 0 returned early</span>
    r = Base.oneto(remainder)
    <span class=hljs-comment ># product_5 seemed fast for small inputs</span>
    <span class=hljs-keyword >return</span> ret + <span class=hljs-meta >@views</span> product_5(x[r], M[r,r])
<span class=hljs-keyword >end</span></code></pre> <p>Now performance is starting to look pretty good:</p> <pre><code class="julia hljs">julia&gt; <span class=hljs-meta >@btime</span> product_8($x, $B)
  <span class=hljs-number >987.308</span> ns (<span class=hljs-number >0</span> allocations: <span class=hljs-number >0</span> bytes)
<span class=hljs-number >508214.49429146945</span></code></pre> <p>We&#39;re now under 1 microsecond, leaving all the competition well behind, so I think I&#39;ll call it quits for today.</p> <p>LIKWID results:</p> <pre><code class="julia hljs">┌────────────────────────────────────────┬─────────────┐
│                                 Metric │    Thread <span class=hljs-number >1</span> │
│                                 <span class=hljs-built_in >String</span> │     <span class=hljs-built_in >Float64</span> │
├────────────────────────────────────────┼─────────────┤
│                    Runtime (RDTSC) [s] │     <span class=hljs-number >1.16956</span> │
│                   Runtime unhalted [s] │     <span class=hljs-number >1.10838</span> │
│                                    CPI │    <span class=hljs-number >0.437218</span> │
│                           DP [MFLOP/s] │     <span class=hljs-number >28353.2</span> │
│                    AVX512 DP [MFLOP/s] │     <span class=hljs-number >28350.3</span> │
│                       Packed [MUOPS/s] │     <span class=hljs-number >3544.51</span> │
│                       Scalar [MUOPS/s] │     <span class=hljs-number >1.46549</span> │
│                    Vectorization ratio │     <span class=hljs-number >99.9587</span> │
│                 Total execution stalls │    <span class=hljs-number >3.9451e8</span> │
│        Stalls caused by L1D misses [%] │     <span class=hljs-number >111.613</span> │
│         Stalls caused by L2 misses [%] │     <span class=hljs-number >6.21932</span> │
│               Execution stall rate [%] │     <span class=hljs-number >11.7638</span> │
│   Stalls caused by L1D misses rate [%] │     <span class=hljs-number >13.1299</span> │
│    Stalls caused by L2 misses rate [%] │    <span class=hljs-number >0.731625</span> │
│ Stalls caused by memory loads rate [%] │     <span class=hljs-number >13.9601</span> │
│     L2 to L1 load bandwidth [MBytes/s] │    <span class=hljs-number >125761.0</span> │
│     L2 to L1 load data volume [GBytes] │     <span class=hljs-number >147.678</span> │
│    L1 to L2 evict bandwidth [MBytes/s] │     <span class=hljs-number >633.472</span> │
│    L1 to L2 evict data volume [GBytes] │    <span class=hljs-number >0.743871</span> │
│     L1 to/from L2 bandwidth [MBytes/s] │   <span class=hljs-number >1.26395e5</span> │
│     L1 to/from L2 data volume [GBytes] │     <span class=hljs-number >148.422</span> │
│              Branch misprediction rate │ <span class=hljs-number >0.000247131</span> │
│                Instructions per branch │     <span class=hljs-number >11.7534</span> │
└────────────────────────────────────────┴─────────────┘</code></pre> <p>While we lost our impressive CPI &#40;although still over 2 IPC&#41;, this implementation required little more than half as many CPU instructions as any of the other implementations. Without unrolling, each inner loop iteration required a load from <code>x</code>, a load from <code>A</code>, and an fma instruction. On a CPU such as this one, capable of 2 aligned loads and 2 fma &#40;fused multiply add&#41; instructions per clock cycle, removing most of the <code>x&#91;j&#93;</code> reloads from the inner loop thus lifts a bottleneck from the inner most loop. Because that bottleneck existed in the form of a huge number of unnecessary instructions, we don&#39;t see removing these instructions show up in improved CPI, but simply in a far lower instruction count. The instruction counts per call were about <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>7605</mn></mrow><annotation encoding="application/x-tex">7605</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.64444em;vertical-align:0em;"></span><span class=mord >7</span><span class=mord >6</span><span class=mord >0</span><span class=mord >5</span></span></span></span>, <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>14097</mn></mrow><annotation encoding="application/x-tex">14097</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.64444em;vertical-align:0em;"></span><span class=mord >1</span><span class=mord >4</span><span class=mord >0</span><span class=mord >9</span><span class=mord >7</span></span></span></span>, and <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>14225</mn></mrow><annotation encoding="application/x-tex">14225</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.64444em;vertical-align:0em;"></span><span class=mord >1</span><span class=mord >4</span><span class=mord >2</span><span class=mord >2</span><span class=mord >5</span></span></span></span> for <code>product_8</code>, <code>product_7</code>, and <code>product_2</code>, respectively.</p> <p>I used small arrays that fit into this CPU&#39;s large 1MiB L2 cache &#40;which could fit a 360x360 matrix and vector&#41;, so that we weren&#39;t limited on memory bandwidth and could focus on interesting optimizations. As the arrays grow larger, it turns into a problem of streaming the matrix through memory, where there isn&#39;t really anything that can be done, aside from multithreading &#40;to first allow splitting up the problem among many core&#39;s L2 caches, and then ultimately to take advantage of the higher memory bandwidth multiple cores have access to vs a single core&#41;.</p> <p>Another important note is that this implementation optimistically assumes that <code>stride&#40;A,2&#41;&#37;8&#61;&#61;0</code>.</p> <p>If we want to try and address alignment, we could consider taking <code>product_7</code>, and then initially pealing off enough initial iterations of the inner loop to align it. Not crossing 64 byte boundaries with loads from <code>A</code> will make them cheaper, but at the cost of reloading <code>x</code> more often. Given aligned loads and a vector width of <code>8</code>, we could estimate the cost of this as roughly <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mrow><mo fence=true >(</mo><mfrac><mi>N</mi><mn>8</mn></mfrac><mo fence=true >)</mo></mrow><mrow><mo fence=true >(</mo><mfrac><mi>N</mi><mn>8</mn></mfrac><mo fence=true >)</mo></mrow><mo>+</mo><mfrac><mrow><mi>N</mi><mo stretchy=false >(</mo><mi>N</mi><mo>+</mo><mn>1</mn><mo stretchy=false >)</mo></mrow><mrow><mn>2</mn><mo>⋅</mo><mn>8</mn></mrow></mfrac><mo>+</mo><mi>N</mi><mo>=</mo><mfrac><msup><mi>N</mi><mn>2</mn></msup><mn>64</mn></mfrac><mo>+</mo><mfrac><mrow><mo stretchy=false >(</mo><mi>N</mi><mo stretchy=false >(</mo><mi>N</mi><mo>+</mo><mn>1</mn><mo stretchy=false >)</mo><mo stretchy=false >)</mo></mrow><mn>16</mn></mfrac><mo>+</mo><mi>N</mi></mrow><annotation encoding="application/x-tex">\left(\frac{N}{8}\right)\left(\frac{N}{8}\right) + \frac{N(N+1)}{2\cdot 8} + N = \frac{N^2}{64} + \frac{(N(N+1))}{16} + N</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:1.222341em;vertical-align:-0.35001em;"></span><span class=minner ><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size1">(</span></span><span class=mord ><span class="mopen nulldelimiter"></span><span class=mfrac ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.872331em;"><span style="top:-2.6550000000000002em;"><span class=pstrut  style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">8</span></span></span></span><span style="top:-3.23em;"><span class=pstrut  style="height:3em;"></span><span class=frac-line  style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class=pstrut  style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span></span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size1">)</span></span></span><span class=mspace  style="margin-right:0.16666666666666666em;"></span><span class=minner ><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size1">(</span></span><span class=mord ><span class="mopen nulldelimiter"></span><span class=mfrac ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.872331em;"><span style="top:-2.6550000000000002em;"><span class=pstrut  style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">8</span></span></span></span><span style="top:-3.23em;"><span class=pstrut  style="height:3em;"></span><span class=frac-line  style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class=pstrut  style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span></span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size1">)</span></span></span><span class=mspace  style="margin-right:0.2222222222222222em;"></span><span class=mbin >+</span><span class=mspace  style="margin-right:0.2222222222222222em;"></span></span><span class=base ><span class=strut  style="height:1.355em;vertical-align:-0.345em;"></span><span class=mord ><span class="mopen nulldelimiter"></span><span class=mfrac ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:1.01em;"><span style="top:-2.6550000000000002em;"><span class=pstrut  style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span><span class="mbin mtight">⋅</span><span class="mord mtight">8</span></span></span></span><span style="top:-3.23em;"><span class=pstrut  style="height:3em;"></span><span class=frac-line  style="border-bottom-width:0.04em;"></span></span><span style="top:-3.485em;"><span class=pstrut  style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span><span class="mbin mtight">+</span><span class="mord mtight">1</span><span class="mclose mtight">)</span></span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class=mspace  style="margin-right:0.2222222222222222em;"></span><span class=mbin >+</span><span class=mspace  style="margin-right:0.2222222222222222em;"></span></span><span class=base ><span class=strut  style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span><span class=mrel >=</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span></span><span class=base ><span class=strut  style="height:1.36292em;vertical-align:-0.345em;"></span><span class=mord ><span class="mopen nulldelimiter"></span><span class=mfrac ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:1.01792em;"><span style="top:-2.6550000000000002em;"><span class=pstrut  style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">6</span><span class="mord mtight">4</span></span></span></span><span style="top:-3.23em;"><span class=pstrut  style="height:3em;"></span><span class=frac-line  style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class=pstrut  style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span><span class=msupsub ><span class=vlist-t ><span class=vlist-r ><span class=vlist  style="height:0.8913142857142857em;"><span style="top:-2.931em;margin-right:0.07142857142857144em;"><span class=pstrut  style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class=mspace  style="margin-right:0.2222222222222222em;"></span><span class=mbin >+</span><span class=mspace  style="margin-right:0.2222222222222222em;"></span></span><span class=base ><span class=strut  style="height:1.355em;vertical-align:-0.345em;"></span><span class=mord ><span class="mopen nulldelimiter"></span><span class=mfrac ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:1.01em;"><span style="top:-2.6550000000000002em;"><span class=pstrut  style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mord mtight">6</span></span></span></span><span style="top:-3.23em;"><span class=pstrut  style="height:3em;"></span><span class=frac-line  style="border-bottom-width:0.04em;"></span></span><span style="top:-3.485em;"><span class=pstrut  style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span><span class="mbin mtight">+</span><span class="mord mtight">1</span><span class="mclose mtight">)</span><span class="mclose mtight">)</span></span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class=mspace  style="margin-right:0.2222222222222222em;"></span><span class=mbin >+</span><span class=mspace  style="margin-right:0.2222222222222222em;"></span></span><span class=base ><span class=strut  style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span></span></span></span>. The <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mrow><mo fence=true >(</mo><mfrac><mi>N</mi><mn>8</mn></mfrac><mo fence=true >)</mo></mrow><mrow><mo fence=true >(</mo><mfrac><mi>N</mi><mn>8</mn></mfrac><mo fence=true >)</mo></mrow></mrow><annotation encoding="application/x-tex">\left(\frac{N}{8}\right)\left(\frac{N}{8}\right)</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:1.222341em;vertical-align:-0.35001em;"></span><span class=minner ><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size1">(</span></span><span class=mord ><span class="mopen nulldelimiter"></span><span class=mfrac ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.872331em;"><span style="top:-2.6550000000000002em;"><span class=pstrut  style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">8</span></span></span></span><span style="top:-3.23em;"><span class=pstrut  style="height:3em;"></span><span class=frac-line  style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class=pstrut  style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span></span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size1">)</span></span></span><span class=mspace  style="margin-right:0.16666666666666666em;"></span><span class=minner ><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size1">(</span></span><span class=mord ><span class="mopen nulldelimiter"></span><span class=mfrac ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.872331em;"><span style="top:-2.6550000000000002em;"><span class=pstrut  style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">8</span></span></span></span><span style="top:-3.23em;"><span class=pstrut  style="height:3em;"></span><span class=frac-line  style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class=pstrut  style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span></span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size1">)</span></span></span></span></span></span> reflects the <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mi>N</mi><mn>8</mn></mfrac></mrow><annotation encoding="application/x-tex">\frac{N}{8}</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:1.217331em;vertical-align:-0.345em;"></span><span class=mord ><span class="mopen nulldelimiter"></span><span class=mfrac ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.872331em;"><span style="top:-2.6550000000000002em;"><span class=pstrut  style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">8</span></span></span></span><span style="top:-3.23em;"><span class=pstrut  style="height:3em;"></span><span class=frac-line  style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class=pstrut  style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span></span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span> outer loop iterations times the <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mi>N</mi><mi>W</mi></mfrac><mo>=</mo><mfrac><mi>N</mi><mn>8</mn></mfrac></mrow><annotation encoding="application/x-tex">\frac{N}{W}=\frac{N}{8}</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:1.217331em;vertical-align:-0.345em;"></span><span class=mord ><span class="mopen nulldelimiter"></span><span class=mfrac ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.872331em;"><span style="top:-2.6550000000000002em;"><span class=pstrut  style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">W</span></span></span></span><span style="top:-3.23em;"><span class=pstrut  style="height:3em;"></span><span class=frac-line  style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class=pstrut  style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span></span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class=mspace  style="margin-right:0.2777777777777778em;"></span><span class=mrel >=</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span></span><span class=base ><span class=strut  style="height:1.217331em;vertical-align:-0.345em;"></span><span class=mord ><span class="mopen nulldelimiter"></span><span class=mfrac ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.872331em;"><span style="top:-2.6550000000000002em;"><span class=pstrut  style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">8</span></span></span></span><span style="top:-3.23em;"><span class=pstrut  style="height:3em;"></span><span class=frac-line  style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class=pstrut  style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span></span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span> loads per inner loop iteration. The <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi>N</mi><mo stretchy=false >(</mo><mi>N</mi><mo>+</mo><mn>1</mn><mo stretchy=false >)</mo></mrow><mn>2</mn></mfrac></mrow><annotation encoding="application/x-tex">\frac{N(N+1)}{2}</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:1.355em;vertical-align:-0.345em;"></span><span class=mord ><span class="mopen nulldelimiter"></span><span class=mfrac ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:1.01em;"><span style="top:-2.6550000000000002em;"><span class=pstrut  style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span><span style="top:-3.23em;"><span class=pstrut  style="height:3em;"></span><span class=frac-line  style="border-bottom-width:0.04em;"></span></span><span style="top:-3.485em;"><span class=pstrut  style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span><span class="mbin mtight">+</span><span class="mord mtight">1</span><span class="mclose mtight">)</span></span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span> are the number of elements we&#39;re loading from <code>A</code>, then the <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mn>1</mn><mn>8</mn></mfrac></mrow><annotation encoding="application/x-tex">\frac{1}{8}</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:1.190108em;vertical-align:-0.345em;"></span><span class=mord ><span class="mopen nulldelimiter"></span><span class=mfrac ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.845108em;"><span style="top:-2.6550000000000002em;"><span class=pstrut  style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">8</span></span></span></span><span style="top:-3.23em;"><span class=pstrut  style="height:3em;"></span><span class=frac-line  style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class=pstrut  style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span> is again dividing by <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>W</mi></mrow><annotation encoding="application/x-tex">W</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">W</span></span></span></span>. The final <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>+</mo><mi>N</mi></mrow><annotation encoding="application/x-tex">+ N</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.76666em;vertical-align:-0.08333em;"></span><span class=mord >+</span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span></span></span></span> are the loads <code>x&#91;i&#93;</code>, insignificant thanks to the smaller exponent.</p> <p>The base pointer of a large array, e.g. <code>A</code>, will normally be 64 byte aligned.</p> <pre><code class="julia hljs">julia&gt; <span class=hljs-built_in >Int</span>(pointer(A))%<span class=hljs-number >64</span>
<span class=hljs-number >0</span></code></pre> <p>Assuming this, the worst case scenario for alignment would be that <code>isodd&#40;stride&#40;A,2&#41;&#37;8&#41;</code>. Then, with AVX512, only 1 out of 8 columns will be aligned.</p> <p>With that, the cost of loading from <code>A</code> becomes </p> <span class=katex-display ><span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML" display=block ><semantics><mtable rowspacing=0.24999999999999992em  columnalign=right  columnspacing=""><mtr><mtd><mstyle scriptlevel=0  displaystyle=true ><mrow><mrow><mo fence=true >(</mo><mfrac><mrow><mi>N</mi><mo stretchy=false >(</mo><mi>N</mi><mo>+</mo><mn>1</mn><mo stretchy=false >)</mo></mrow><mn>16</mn></mfrac><mo fence=true >)</mo></mrow><mrow><mo fence=true >(</mo><mfrac><mrow><mn>2</mn><mo>⋅</mo><mn>7</mn></mrow><mn>8</mn></mfrac><mo fence=true >)</mo></mrow><mo>+</mo><mrow><mo fence=true >(</mo><mfrac><mrow><mi>N</mi><mo stretchy=false >(</mo><mi>N</mi><mo>+</mo><mn>1</mn><mo stretchy=false >)</mo></mrow><mn>16</mn></mfrac><mo fence=true >)</mo></mrow><mrow><mo fence=true >(</mo><mfrac><mn>1</mn><mn>8</mn></mfrac><mo fence=true >)</mo></mrow><mo>=</mo><mfrac><mrow><mn>15</mn><mi>N</mi><mo stretchy=false >(</mo><mi>N</mi><mo>+</mo><mn>1</mn><mo stretchy=false >)</mo></mrow><mn>128</mn></mfrac></mrow></mstyle></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{aligned} \left(\frac{N(N+1)}{16}\right) \left(\frac{2\cdot 7}{8}\right) + \left(\frac{N(N+1)}{16}\right) \left(\frac{1}{8}\right) = \frac{15N(N+1)}{128} \end{aligned}</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:2.70003em;vertical-align:-1.1000150000000002em;"></span><span class=mord ><span class=mtable ><span class=col-align-r ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:1.6000149999999997em;"><span style="top:-3.6000150000000004em;"><span class=pstrut  style="height:3.45em;"></span><span class=mord ><span class=minner ><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size3">(</span></span><span class=mord ><span class="mopen nulldelimiter"></span><span class=mfrac ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:1.427em;"><span style="top:-2.314em;"><span class=pstrut  style="height:3em;"></span><span class=mord ><span class=mord >1</span><span class=mord >6</span></span></span><span style="top:-3.23em;"><span class=pstrut  style="height:3em;"></span><span class=frac-line  style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class=pstrut  style="height:3em;"></span><span class=mord ><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class=mopen >(</span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class=mspace  style="margin-right:0.2222222222222222em;"></span><span class=mbin >+</span><span class=mspace  style="margin-right:0.2222222222222222em;"></span><span class=mord >1</span><span class=mclose >)</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size3">)</span></span></span><span class=mspace  style="margin-right:0.16666666666666666em;"></span><span class=minner ><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size3">(</span></span><span class=mord ><span class="mopen nulldelimiter"></span><span class=mfrac ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:1.32144em;"><span style="top:-2.314em;"><span class=pstrut  style="height:3em;"></span><span class=mord ><span class=mord >8</span></span></span><span style="top:-3.23em;"><span class=pstrut  style="height:3em;"></span><span class=frac-line  style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class=pstrut  style="height:3em;"></span><span class=mord ><span class=mord >2</span><span class=mspace  style="margin-right:0.2222222222222222em;"></span><span class=mbin >⋅</span><span class=mspace  style="margin-right:0.2222222222222222em;"></span><span class=mord >7</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size3">)</span></span></span><span class=mspace  style="margin-right:0.2222222222222222em;"></span><span class=mbin >+</span><span class=mspace  style="margin-right:0.2222222222222222em;"></span><span class=minner ><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size3">(</span></span><span class=mord ><span class="mopen nulldelimiter"></span><span class=mfrac ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:1.427em;"><span style="top:-2.314em;"><span class=pstrut  style="height:3em;"></span><span class=mord ><span class=mord >1</span><span class=mord >6</span></span></span><span style="top:-3.23em;"><span class=pstrut  style="height:3em;"></span><span class=frac-line  style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class=pstrut  style="height:3em;"></span><span class=mord ><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class=mopen >(</span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class=mspace  style="margin-right:0.2222222222222222em;"></span><span class=mbin >+</span><span class=mspace  style="margin-right:0.2222222222222222em;"></span><span class=mord >1</span><span class=mclose >)</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size3">)</span></span></span><span class=mspace  style="margin-right:0.16666666666666666em;"></span><span class=minner ><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size3">(</span></span><span class=mord ><span class="mopen nulldelimiter"></span><span class=mfrac ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:1.32144em;"><span style="top:-2.314em;"><span class=pstrut  style="height:3em;"></span><span class=mord ><span class=mord >8</span></span></span><span style="top:-3.23em;"><span class=pstrut  style="height:3em;"></span><span class=frac-line  style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class=pstrut  style="height:3em;"></span><span class=mord ><span class=mord >1</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size3">)</span></span></span><span class=mspace  style="margin-right:0.2777777777777778em;"></span><span class=mrel >=</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span><span class=mord ><span class="mopen nulldelimiter"></span><span class=mfrac ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:1.427em;"><span style="top:-2.314em;"><span class=pstrut  style="height:3em;"></span><span class=mord ><span class=mord >1</span><span class=mord >2</span><span class=mord >8</span></span></span><span style="top:-3.23em;"><span class=pstrut  style="height:3em;"></span><span class=frac-line  style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class=pstrut  style="height:3em;"></span><span class=mord ><span class=mord >1</span><span class=mord >5</span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class=mopen >(</span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class=mspace  style="margin-right:0.2222222222222222em;"></span><span class=mbin >+</span><span class=mspace  style="margin-right:0.2222222222222222em;"></span><span class=mord >1</span><span class=mclose >)</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:1.1000150000000002em;"><span></span></span></span></span></span></span></span></span></span></span></span> <p>That is, loading from <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal">A</span></span></span></span> becomes <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mn>15</mn><mn>8</mn></mfrac></mrow><annotation encoding="application/x-tex">\frac{15}{8}</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:1.190108em;vertical-align:-0.345em;"></span><span class=mord ><span class="mopen nulldelimiter"></span><span class=mfrac ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.845108em;"><span style="top:-2.6550000000000002em;"><span class=pstrut  style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">8</span></span></span></span><span style="top:-3.23em;"><span class=pstrut  style="height:3em;"></span><span class=frac-line  style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class=pstrut  style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mord mtight">5</span></span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span> times more expensive. We have an increase in cost of <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mn>7</mn><mi>N</mi><mo stretchy=false >(</mo><mi>N</mi><mo>+</mo><mn>1</mn><mo stretchy=false >)</mo></mrow><mn>128</mn></mfrac></mrow><annotation encoding="application/x-tex">\frac{7N(N+1)}{128}</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:1.355em;vertical-align:-0.345em;"></span><span class=mord ><span class="mopen nulldelimiter"></span><span class=mfrac ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:1.01em;"><span style="top:-2.6550000000000002em;"><span class=pstrut  style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mord mtight">2</span><span class="mord mtight">8</span></span></span></span><span style="top:-3.23em;"><span class=pstrut  style="height:3em;"></span><span class=frac-line  style="border-bottom-width:0.04em;"></span></span><span style="top:-3.485em;"><span class=pstrut  style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">7</span><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span><span class="mbin mtight">+</span><span class="mord mtight">1</span><span class="mclose mtight">)</span></span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span>.</p> <p>If we try to address this by pealing loop iterations at the start of each column to align the loads from <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal">A</span></span></span></span>, this causes one of two complications. Either</p> <ol> <li><p>We can no longer unroll the outer loop, increasing the cost of reloading <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">x</span></span></span></span> in the inner loop from <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><msup><mi>N</mi><mn>2</mn></msup><mn>64</mn></mfrac></mrow><annotation encoding="application/x-tex">\frac{N^2}{64}</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:1.36292em;vertical-align:-0.345em;"></span><span class=mord ><span class="mopen nulldelimiter"></span><span class=mfrac ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:1.01792em;"><span style="top:-2.6550000000000002em;"><span class=pstrut  style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">6</span><span class="mord mtight">4</span></span></span></span><span style="top:-3.23em;"><span class=pstrut  style="height:3em;"></span><span class=frac-line  style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class=pstrut  style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span><span class=msupsub ><span class=vlist-t ><span class=vlist-r ><span class=vlist  style="height:0.8913142857142857em;"><span style="top:-2.931em;margin-right:0.07142857142857144em;"><span class=pstrut  style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span> to <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><msup><mi>N</mi><mn>2</mn></msup><mn>8</mn></mfrac></mrow><annotation encoding="application/x-tex">\frac{N^2}{8}</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:1.36292em;vertical-align:-0.345em;"></span><span class=mord ><span class="mopen nulldelimiter"></span><span class=mfrac ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:1.01792em;"><span style="top:-2.6550000000000002em;"><span class=pstrut  style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">8</span></span></span></span><span style="top:-3.23em;"><span class=pstrut  style="height:3em;"></span><span class=frac-line  style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class=pstrut  style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span><span class=msupsub ><span class=vlist-t ><span class=vlist-r ><span class=vlist  style="height:0.8913142857142857em;"><span style="top:-2.931em;margin-right:0.07142857142857144em;"><span class=pstrut  style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span>, an increase in cost of <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mn>16</mn><msup><mi>N</mi><mn>2</mn></msup></mrow><mn>128</mn></mfrac><mo>−</mo><mfrac><mrow><mn>2</mn><msup><mi>N</mi><mn>2</mn></msup></mrow><mn>128</mn></mfrac><mo>=</mo><mfrac><mn>14</mn><mn>128</mn></mfrac></mrow><annotation encoding="application/x-tex">\frac{16N^2}{128} - \frac{2N^2}{128} = \frac{14}{128}</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:1.36292em;vertical-align:-0.345em;"></span><span class=mord ><span class="mopen nulldelimiter"></span><span class=mfrac ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:1.01792em;"><span style="top:-2.6550000000000002em;"><span class=pstrut  style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mord mtight">2</span><span class="mord mtight">8</span></span></span></span><span style="top:-3.23em;"><span class=pstrut  style="height:3em;"></span><span class=frac-line  style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class=pstrut  style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mord mtight">6</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span><span class=msupsub ><span class=vlist-t ><span class=vlist-r ><span class=vlist  style="height:0.8913142857142857em;"><span style="top:-2.931em;margin-right:0.07142857142857144em;"><span class=pstrut  style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class=mspace  style="margin-right:0.2222222222222222em;"></span><span class=mbin >−</span><span class=mspace  style="margin-right:0.2222222222222222em;"></span></span><span class=base ><span class=strut  style="height:1.36292em;vertical-align:-0.345em;"></span><span class=mord ><span class="mopen nulldelimiter"></span><span class=mfrac ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:1.01792em;"><span style="top:-2.6550000000000002em;"><span class=pstrut  style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mord mtight">2</span><span class="mord mtight">8</span></span></span></span><span style="top:-3.23em;"><span class=pstrut  style="height:3em;"></span><span class=frac-line  style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class=pstrut  style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span><span class=msupsub ><span class=vlist-t ><span class=vlist-r ><span class=vlist  style="height:0.8913142857142857em;"><span style="top:-2.931em;margin-right:0.07142857142857144em;"><span class=pstrut  style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class=mspace  style="margin-right:0.2777777777777778em;"></span><span class=mrel >=</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span></span><span class=base ><span class=strut  style="height:1.190108em;vertical-align:-0.345em;"></span><span class=mord ><span class="mopen nulldelimiter"></span><span class=mfrac ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.845108em;"><span style="top:-2.6550000000000002em;"><span class=pstrut  style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mord mtight">2</span><span class="mord mtight">8</span></span></span></span><span style="top:-3.23em;"><span class=pstrut  style="height:3em;"></span><span class=frac-line  style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class=pstrut  style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mord mtight">4</span></span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span>, meaning this is potentially a smaller increase in cost than what the unrolled <code>product_8</code> suffers.</p> <li><p>Still unroll, and use shuffle/permute instructions to try and line up the loads of <code>x</code> correctly with the loads from <code>A</code> that may now all be offset to align them. This approach would require generating different specializations for the different offset patterns, where you&#39;d have fixed shuffle sequences in each one. As we&#39;re dominated by loads, the shuffles may be &quot;free&quot;/able to execute concurrently, making this likely the fastest, but most complicated, approach. This is especially the case for Zen4, which has fairly fast shuffles but slow loads, or for consumer AVX512 Intel CPUs, which can use port 5 for shuffle instructions but not for floating point arithmetic, again making shuffles more or less &quot;free&quot; to execute concurrently with loads and floating point.</p> </ol> <p>P.S. A goal of <code>LoopModels</code> will be that <code>@turbo</code> will generate code as fast or faster than the above for code as simple as</p> <pre><code class="julia hljs"><span class=hljs-meta >@turbo</span> <span class=hljs-keyword >function</span> dotturbo(x, A)
    s = zero(Base.promote_eltype(x, A))
    <span class=hljs-meta >@assert</span> eachindex(x) == axes(A,<span class=hljs-number >1</span>) == axes(A,<span class=hljs-number >2</span>)
    <span class=hljs-keyword >for</span> i = eachindex(x), j = eachindex(x)
        s += x[i] * A[i,j] * x[j]
    <span class=hljs-keyword >end</span>
    s
<span class=hljs-keyword >end</span></code></pre> <p>when <code>A isa Symmetric</code>, and again of course doing the right thing when <code>A isa Adjoint</code>, or simple <code>A isa Matrix</code>. Our code should express our intent, simple and generic. The compiler should find out how to do the right thing for the types.</p> <div class=page-foot > <div class="copyright bt b--moon-gray mt4 pt2"> <small class=silver > &copy; Chris Elrod, Yingbo Ma. Last modified: December 27, 2022. Website built with <a href="https://github.com/tlienart/Franklin.jl">Franklin.jl</a> and the <a href="https://julialang.org">Julia programming language</a>. </small> </div> </div> </div> </div>